{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(['id', 'target'], axis=1), train['target'], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare encoder for both validation and test data\n",
    "en_cols = X_train.columns.tolist()\n",
    "looe = LeaveOneOutEncoder(cols=en_cols).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform validation and test data\n",
    "proc_test = looe.transform(test.drop('id', axis=1))\n",
    "X_test = looe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data by stratified Kfold to add noises to the training set\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    X_dev = X_train.iloc[train_index]\n",
    "    y_dev = y_train.iloc[train_index]\n",
    "    X_val = X_train.iloc[test_index]\n",
    "    y_val = y_train.iloc[test_index]\n",
    "    looe_temp = LeaveOneOutEncoder(cols=en_cols).fit(X_dev, y_dev)\n",
    "    X_train_l.append(looe_temp.transform(X_val))\n",
    "    y_train_l.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalise the training data\n",
    "X_train = pd.concat(X_train_l)\n",
    "y_train = pd.concat(y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\p1319163\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.7994153379667676\n"
     ]
    }
   ],
   "source": [
    "# lr performance\n",
    "print(\"ROCAUC score: {}\".format(roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=10, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "              n_jobs=7, nthread=None, objective='binary:logistic',\n",
       "              random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=2.268, seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost \n",
    "xgb = XGBClassifier(max_depth=10, \n",
    "                    n_estimators=1000, \n",
    "                    learning_rate=0.01, \n",
    "                    n_jobs=7, \n",
    "                    random_state=42, \n",
    "                    scale_pos_weight=2.268)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.7940303716319459\n"
     ]
    }
   ],
   "source": [
    "# xgb performance\n",
    "print(\"ROCAUC score: {}\".format(roc_auc_score(y_test, xgb.predict_proba(X_test)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.01,\n",
       "                   n_estimators=5000, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboost\n",
    "ada = AdaBoostClassifier(n_estimators=5000, learning_rate=0.01, random_state=42)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.7975746003420995\n"
     ]
    }
   ],
   "source": [
    "# ada performance\n",
    "print(\"ROCAUC score: {}\".format(roc_auc_score(y_test, ada.predict_proba(X_test)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192000 samples, validate on 48000 samples\n",
      "Epoch 1/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.5832 - auroc: 0.6431 - val_loss: 0.5339 - val_auroc: 0.7462\n",
      "Epoch 2/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.5259 - auroc: 0.7582 - val_loss: 0.5063 - val_auroc: 0.7799\n",
      "Epoch 3/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.5065 - auroc: 0.7809 - val_loss: 0.4964 - val_auroc: 0.7939\n",
      "Epoch 4/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4985 - auroc: 0.7897 - val_loss: 0.4886 - val_auroc: 0.7982\n",
      "Epoch 5/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4953 - auroc: 0.7933 - val_loss: 0.4859 - val_auroc: 0.8003\n",
      "Epoch 6/1000\n",
      "192000/192000 [==============================] - 4s 21us/step - loss: 0.4945 - auroc: 0.7941 - val_loss: 0.4863 - val_auroc: 0.8011\n",
      "Epoch 7/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4939 - auroc: 0.7951 - val_loss: 0.4887 - val_auroc: 0.8011\n",
      "Epoch 8/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4937 - auroc: 0.7952 - val_loss: 0.4970 - val_auroc: 0.8016\n",
      "Epoch 9/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4934 - auroc: 0.7951 - val_loss: 0.4881 - val_auroc: 0.8019\n",
      "Epoch 10/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4933 - auroc: 0.7954 - val_loss: 0.4863 - val_auroc: 0.8020\n",
      "Epoch 11/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4933 - auroc: 0.7955 - val_loss: 0.4888 - val_auroc: 0.8019\n",
      "Epoch 12/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4928 - auroc: 0.7953 - val_loss: 0.4880 - val_auroc: 0.8020\n",
      "Epoch 13/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4925 - auroc: 0.7955 - val_loss: 0.4842 - val_auroc: 0.8021\n",
      "Epoch 14/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4927 - auroc: 0.7955 - val_loss: 0.4854 - val_auroc: 0.8021\n",
      "Epoch 15/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4928 - auroc: 0.7956 - val_loss: 0.4841 - val_auroc: 0.8021\n",
      "Epoch 16/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4927 - auroc: 0.7960 - val_loss: 0.4903 - val_auroc: 0.8021\n",
      "Epoch 17/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4924 - auroc: 0.7956 - val_loss: 0.4879 - val_auroc: 0.8021\n",
      "Epoch 18/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4926 - auroc: 0.7954 - val_loss: 0.4867 - val_auroc: 0.8022\n",
      "Epoch 19/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4925 - auroc: 0.7955 - val_loss: 0.4841 - val_auroc: 0.8023\n",
      "Epoch 20/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4921 - auroc: 0.7955 - val_loss: 0.4853 - val_auroc: 0.8024\n",
      "Epoch 21/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4924 - auroc: 0.7958 - val_loss: 0.4840 - val_auroc: 0.8023\n",
      "Epoch 22/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4920 - auroc: 0.7957 - val_loss: 0.4852 - val_auroc: 0.8024\n",
      "Epoch 23/1000\n",
      "192000/192000 [==============================] - 4s 22us/step - loss: 0.4926 - auroc: 0.7958 - val_loss: 0.4842 - val_auroc: 0.8023\n",
      "Epoch 24/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4925 - auroc: 0.7961 - val_loss: 0.4843 - val_auroc: 0.8023\n",
      "Epoch 25/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4923 - auroc: 0.7959 - val_loss: 0.4842 - val_auroc: 0.8026\n",
      "Epoch 26/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4916 - auroc: 0.7958 - val_loss: 0.4866 - val_auroc: 0.8025\n",
      "Epoch 27/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4921 - auroc: 0.7962 - val_loss: 0.4838 - val_auroc: 0.8026\n",
      "Epoch 28/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4922 - auroc: 0.7960 - val_loss: 0.4844 - val_auroc: 0.8026\n",
      "Epoch 29/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4918 - auroc: 0.7960 - val_loss: 0.4837 - val_auroc: 0.8025\n",
      "Epoch 30/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4911 - auroc: 0.7963 - val_loss: 0.4847 - val_auroc: 0.8027\n",
      "Epoch 31/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4922 - auroc: 0.7961 - val_loss: 0.4838 - val_auroc: 0.8025\n",
      "Epoch 32/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4914 - auroc: 0.7959 - val_loss: 0.4856 - val_auroc: 0.8026\n",
      "Epoch 33/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4916 - auroc: 0.7963 - val_loss: 0.4862 - val_auroc: 0.8027\n",
      "Epoch 34/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4917 - auroc: 0.7960 - val_loss: 0.4841 - val_auroc: 0.8026\n",
      "Epoch 35/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4921 - auroc: 0.7960 - val_loss: 0.4845 - val_auroc: 0.8026\n",
      "Epoch 36/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4915 - auroc: 0.7965 - val_loss: 0.4837 - val_auroc: 0.8029\n",
      "Epoch 37/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4920 - auroc: 0.7961 - val_loss: 0.4843 - val_auroc: 0.8026\n",
      "Epoch 38/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4914 - auroc: 0.7959 - val_loss: 0.4835 - val_auroc: 0.8026\n",
      "Epoch 39/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4913 - auroc: 0.7966 - val_loss: 0.4835 - val_auroc: 0.8025\n",
      "Epoch 40/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4911 - auroc: 0.7962 - val_loss: 0.4867 - val_auroc: 0.8027\n",
      "Epoch 41/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4911 - auroc: 0.7963 - val_loss: 0.4836 - val_auroc: 0.8026\n",
      "Epoch 42/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4913 - auroc: 0.7965 - val_loss: 0.4849 - val_auroc: 0.8028\n",
      "Epoch 43/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4910 - auroc: 0.7961 - val_loss: 0.4841 - val_auroc: 0.8027\n",
      "Epoch 44/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4915 - auroc: 0.7962 - val_loss: 0.4838 - val_auroc: 0.8025\n",
      "Epoch 45/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4911 - auroc: 0.7962 - val_loss: 0.5166 - val_auroc: 0.8026\n",
      "Epoch 46/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4911 - auroc: 0.7963 - val_loss: 0.4848 - val_auroc: 0.8028\n",
      "Epoch 47/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4907 - auroc: 0.7961 - val_loss: 0.4866 - val_auroc: 0.8028\n",
      "Epoch 48/1000\n",
      "192000/192000 [==============================] - 4s 22us/step - loss: 0.4911 - auroc: 0.7964 - val_loss: 0.4835 - val_auroc: 0.8029\n",
      "Epoch 49/1000\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.4912 - auroc: 0.7966 - val_loss: 0.4838 - val_auroc: 0.8028\n",
      "Epoch 50/1000\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.4909 - auroc: 0.7965 - val_loss: 0.4845 - val_auroc: 0.8028\n",
      "Epoch 51/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4908 - auroc: 0.7964 - val_loss: 0.4833 - val_auroc: 0.8028\n",
      "Epoch 52/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4907 - auroc: 0.7964 - val_loss: 0.4834 - val_auroc: 0.8029\n",
      "Epoch 53/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4907 - auroc: 0.7962 - val_loss: 0.4874 - val_auroc: 0.8029\n",
      "Epoch 54/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4906 - auroc: 0.7964 - val_loss: 0.4831 - val_auroc: 0.8030\n",
      "Epoch 55/1000\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.4909 - auroc: 0.7962 - val_loss: 0.4834 - val_auroc: 0.8031\n",
      "Epoch 56/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4906 - auroc: 0.7965 - val_loss: 0.4843 - val_auroc: 0.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "192000/192000 [==============================] - 4s 22us/step - loss: 0.4911 - auroc: 0.7966 - val_loss: 0.4831 - val_auroc: 0.8029\n",
      "Epoch 58/1000\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.4906 - auroc: 0.7966 - val_loss: 0.4848 - val_auroc: 0.8029\n",
      "Epoch 59/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4911 - auroc: 0.7965 - val_loss: 0.4839 - val_auroc: 0.8031\n",
      "Epoch 60/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4907 - auroc: 0.7965 - val_loss: 0.4832 - val_auroc: 0.8032\n",
      "Epoch 61/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4907 - auroc: 0.7963 - val_loss: 0.4861 - val_auroc: 0.8031\n",
      "Epoch 62/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4911 - auroc: 0.7963 - val_loss: 0.4831 - val_auroc: 0.8030\n",
      "Epoch 63/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4906 - auroc: 0.7965 - val_loss: 0.4953 - val_auroc: 0.8030\n",
      "Epoch 64/1000\n",
      "192000/192000 [==============================] - 3s 17us/step - loss: 0.4903 - auroc: 0.7967 - val_loss: 0.4833 - val_auroc: 0.8032\n",
      "Epoch 65/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4904 - auroc: 0.7966 - val_loss: 0.4831 - val_auroc: 0.8031\n",
      "Epoch 66/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4909 - auroc: 0.7966 - val_loss: 0.4859 - val_auroc: 0.8029\n",
      "Epoch 67/1000\n",
      "192000/192000 [==============================] - 4s 21us/step - loss: 0.4907 - auroc: 0.7968 - val_loss: 0.4881 - val_auroc: 0.8030\n",
      "Epoch 68/1000\n",
      "192000/192000 [==============================] - 4s 21us/step - loss: 0.4908 - auroc: 0.7966 - val_loss: 0.4863 - val_auroc: 0.8032\n",
      "Epoch 69/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4907 - auroc: 0.7965 - val_loss: 0.4831 - val_auroc: 0.8031\n",
      "Epoch 70/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4907 - auroc: 0.7967 - val_loss: 0.4837 - val_auroc: 0.8030\n",
      "Epoch 71/1000\n",
      "192000/192000 [==============================] - 3s 18us/step - loss: 0.4904 - auroc: 0.7968 - val_loss: 0.4833 - val_auroc: 0.8030\n",
      "Epoch 72/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4905 - auroc: 0.7969 - val_loss: 0.4874 - val_auroc: 0.8030\n",
      "Epoch 73/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4906 - auroc: 0.7970 - val_loss: 0.4838 - val_auroc: 0.8030\n",
      "Epoch 74/1000\n",
      "192000/192000 [==============================] - 4s 22us/step - loss: 0.4903 - auroc: 0.7965 - val_loss: 0.4855 - val_auroc: 0.8032\n",
      "Epoch 75/1000\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.4904 - auroc: 0.7969 - val_loss: 0.4857 - val_auroc: 0.8032\n",
      "Epoch 76/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4903 - auroc: 0.7964 - val_loss: 0.4909 - val_auroc: 0.8030\n",
      "Epoch 77/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4903 - auroc: 0.7969 - val_loss: 0.4902 - val_auroc: 0.8032\n",
      "Epoch 78/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4902 - auroc: 0.7967 - val_loss: 0.4832 - val_auroc: 0.8031\n",
      "Epoch 79/1000\n",
      "192000/192000 [==============================] - 4s 18us/step - loss: 0.4904 - auroc: 0.7969 - val_loss: 0.4840 - val_auroc: 0.8031\n",
      "Epoch 80/1000\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.4905 - auroc: 0.7968 - val_loss: 0.4830 - val_auroc: 0.8031\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0a578d208>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network\n",
    "es = EarlyStopping(monitor='val_auroc', mode='max', verbose=1, min_delta=0.001, patience=50)\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(23, input_dim=23, activation='relu'))\n",
    "nn.add(Dense(12, activation='relu'))\n",
    "nn.add(Dense(1, activation='sigmoid'))\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auroc])\n",
    "nn.fit(X_train, y_train, \n",
    "       batch_size=128, \n",
    "       epochs=1000, \n",
    "       verbose=1, \n",
    "       callbacks=[es], \n",
    "       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.7990699339145892\n"
     ]
    }
   ],
   "source": [
    "# nn performance\n",
    "print(\"ROCAUC score: {}\".format(roc_auc_score(y_test, nn.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lr model -> public score 0.80288\n",
    "lr_out = pd.DataFrame({'id': test['id'], 'target': lr.predict_proba(proc_test)[:,1]})\n",
    "lr_out.to_csv(\"../submissions/lr-tar-noise-submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction results for all models\n",
    "xgb_out = pd.DataFrame({'id': test['id'], 'target': xgb.predict_proba(proc_test)[:,1]})\n",
    "ada_out = pd.DataFrame({'id': test['id'], 'target': ada.predict_proba(proc_test)[:,1]})\n",
    "nn_out = pd.DataFrame({'id': test['id'], 'target':[i[0] for i in nn.predict_proba(proc_test)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble results from these 4 models -> 0.80295\n",
    "ens_out = (lr_out + xgb_out + ada_out + nn_out) / 4\n",
    "ens_out['id'] = ens_out['id'].astype(int)\n",
    "ens_out.to_csv(\"../submissions/ens-tar-noise-submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn model -> 0.80254\n",
    "nn_out.to_csv(\"../submissions/nn-tar-noise-submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
